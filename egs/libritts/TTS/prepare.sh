#!/usr/bin/env bash

# fix segmentation fault reported in https://github.com/k2-fsa/icefall/issues/674
export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python

set -eou pipefail

stage=0
stop_stage=100

dl_dir=$PWD/download

. shared/parse_options.sh || exit 1

# All files generated by this script are saved in "data".
# You can safely remove "data" and rerun this script to regenerate it.
mkdir -p data

log() {
  # This function is from espnet
  local fname=${BASH_SOURCE[1]##*/}
  echo -e "$(date '+%Y-%m-%d %H:%M:%S') (${fname}:${BASH_LINENO[0]}:${FUNCNAME[1]}) $*"
}

log "dl_dir: $dl_dir"

if [ $stage -le -1 ] && [ $stop_stage -ge -1 ]; then
  log "Stage -1: build monotonic_align lib"
  if [ ! -d vits/monotonic_align/build ]; then
    cd vits/monotonic_align
    python setup.py build_ext --inplace
    cd ../../
  else 
    log "monotonic_align lib already built"
  fi
fi

if [ $stage -le 0 ] && [ $stop_stage -ge 0 ]; then
  log "Stage 0: Download data"

  # If you have pre-downloaded it to /path/to/LibriTTS,
  # you can create a symlink
  #
  #   ln -sfv /path/to/LibriTTS $dl_dir/LibriTTS
  #
  if [ ! -d $dl_dir/LibriTTS ]; then
    lhotse download libritts $dl_dir
  fi
fi

if [ $stage -le 1 ] && [ $stop_stage -ge 1 ]; then
  log "Stage 1: Prepare LibriTTS manifest"
  # We assume that you have downloaded the LibriTTS corpus
  # to $dl_dir/LibriTTS
  mkdir -p data/manifests
  if [ ! -e data/manifests/.libritts.done ]; then
    lhotse prepare libritts $dl_dir/LibriTTS data/manifests
    touch data/manifests/.libritts.done
  fi
fi

if [ $stage -le 2 ] && [ $stop_stage -ge 2 ]; then
  log "Stage 2: Compute spectrogram for LibriTTS"
  mkdir -p data/spectrogram
  if [ ! -e data/spectrogram/.libritts.done ]; then
    ./local/compute_spectrogram_libritts.py
    touch data/spectrogram/.libritts.done
  fi

  # Here we shuffle and combine the train-clean-100, train-clean-360 and 
  # train-other-500 together to form the training set.
  if [ ! -f data/spectrogram/libritts_cuts_train-all-shuf.jsonl.gz ]; then
    cat <(gunzip -c data/spectrogram/libritts_cuts_train-clean-100.jsonl.gz) \
      <(gunzip -c data/spectrogram/libritts_cuts_train-clean-360.jsonl.gz) \
      <(gunzip -c data/spectrogram/libritts_cuts_train-other-500.jsonl.gz) | \
      shuf | gzip -c > data/spectrogram/libritts_cuts_train-all-shuf.jsonl.gz
  fi

  if [ ! -e data/spectrogram/.libritts-validated.done ]; then
    log "Validating data/spectrogram for LibriTTS"
    ./local/validate_manifest.py \
      data/spectrogram/libritts_cuts_train-all-shuf.jsonl.gz
    touch data/spectrogram/.libritts-validated.done
  fi
fi

if [ $stage -le 3 ] && [ $stop_stage -ge 3 ]; then
  log "Stage 3: Prepare phoneme tokens for LibriTTS"
  if [ ! -e data/spectrogram/.libritts_with_token.done ]; then
    ./local/prepare_tokens_libritts.py
    mv data/spectrogram/libritts_cuts_with_tokens_train-all-shuf.jsonl.gz \
      data/spectrogram/libritts_cuts_train-all-shuf.jsonl.gz
    touch data/spectrogram/.libritts_with_token.done
  fi
fi

if [ $stage -le 4 ] && [ $stop_stage -ge 4 ]; then
  log "Stage 4: Generate token file"
  # We assume you have installed g2p_en and espnet_tts_frontend.
  # If not, please install them with:
  #   - g2p_en: `pip install g2p_en`, refer to https://github.com/Kyubyong/g2p
  #   - espnet_tts_frontend, `pip install espnet_tts_frontend`, refer to https://github.com/espnet/espnet_tts_frontend/
  if [ ! -e data/tokens.txt ]; then
    ./local/prepare_token_file.py \
      --manifest-file data/spectrogram/libritts_cuts_train-all-shuf.jsonl.gz \
      --tokens data/tokens.txt
  fi
fi

if [ $stage -le 5 ] && [ $stop_stage -ge 5 ]; then
  log "Stage 5: Generate speakers file"
  if [ ! -e data/speakers.txt ]; then
    touch data/speakers.txt
    
    for set in train-clean-100 train-clean-360 train-other-500 dev-clean dev-other test-clean test-other; do
      gunzip -c data/manifests/libritts_supervisions_${set}.jsonl.gz \
        | jq '.speaker' | sed 's/"//g' \
        | sort | uniq >> data/${set}_speakers.txt
    done

    cat data/train-clean-100_speakers.txt \
      data/train-clean-360_speakers.txt data/train-other-500_speakers.txt \
      data/dev-clean_speakers.txt data/dev-other_speakers.txt \
      data/test-clean_speakers.txt data/test-other_speakers.txt \
      | sort | uniq > data/speakers.txt
  fi
fi
